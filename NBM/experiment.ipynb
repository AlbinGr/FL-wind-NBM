{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "sys.path.insert(0, os.path.join(os.getcwd()))\n",
    "from exp_utils import start_exp\n",
    "\n",
    "from experiment_parameter import *\n",
    "from model_parameter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"Exp_2\"\n",
    "\n",
    "if experiment_name == \"Exp_1\":\n",
    "    exp = exp_param(name = \"Exp_1\", max_week = 12, all_start_date = ['2016-12-01 18:30:00', '2017-06-01 18:30:00','2017-03-01 18:30:00','2017-09-01 18:30:00'],\\\n",
    "        all_algorithm = [\"Local\", \"FedAvg\"], device = \"cuda\")\n",
    "\n",
    "if experiment_name == \"Exp_2\": # Longer week traing (only for cross-farm learning) from weeks 14 to 24 every second week. \n",
    "    exp = exp_param(name = \"Exp_2\", max_week = 24, min_week = 13, every_n_week = 2, all_start_date = ['2016-12-01 18:30:00', '2017-06-01 18:30:00','2017-03-01 18:30:00','2017-09-01 18:30:00'],\\\n",
    "        all_algorithm = [\"Local\", \"FedAvg\"], all_cross_farm = [False, True], device = \"cuda\")\n",
    "\n",
    "if experiment_name == \"Exp_3\":\n",
    "    exp = exp_param(name = \"Exp_3\", max_week = 12, all_start_date = ['2016-12-01 18:30:00', '2017-06-01 18:30:00','2017-03-01 18:30:00','2017-09-01 18:30:00'],\\\n",
    "        all_algorithm = [\"FedProx\"], all_cross_farm = [True, False], device = \"cuda\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Preparing clients from 2016-12-01 18:30:00 to 2017-03-09 18:30:00\n",
      "\n",
      "Created client Penmanshiel turbine WT_11 with 3459\n",
      "Created client Penmanshiel turbine WT_12 with 2522\n",
      "Created client Penmanshiel turbine WT_13 with 3147\n",
      "Created client Penmanshiel turbine WT_14 with 2654\n",
      "__________________________________________________________\n",
      "Created client Kelmarsh turbine WT_03 with 10055\n",
      "Created client Kelmarsh turbine WT_04 with 8350\n",
      "Created client Kelmarsh turbine WT_05 with 10450\n",
      "Created client Kelmarsh turbine WT_06 with 10441\n",
      "__________________________________________________________\n",
      "Created client EDP turbine WT_01 with 13960\n",
      "Created client EDP turbine WT_06 with 14113\n",
      "Created client EDP turbine WT_07 with 13816\n",
      "Created client EDP turbine WT_11 with 14113\n",
      "__________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training of the intra_farm algorithms\n",
      "Training of FedAvg\n",
      "\n",
      "\n",
      "\n",
      "Penmanshiel\n",
      "\n",
      "\n",
      "Kelmarsh\n",
      "\n",
      "\n",
      "EDP\n",
      "\n",
      "\n",
      "\n",
      "Training of the cross_farm algorithms\n",
      "Training of FedAvg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Finetuning\n",
      "Finetuning of the intra_farm algorithms\n",
      "Finetuning of FedAvg\n",
      "Finetuning of Penmanshiel_WT_11 for FedAvg with intra_farm\n",
      "Finetuning of Penmanshiel_WT_12 for FedAvg with intra_farm\n",
      "Finetuning of Penmanshiel_WT_13 for FedAvg with intra_farm\n",
      "Finetuning of Penmanshiel_WT_14 for FedAvg with intra_farm\n",
      "Finetuning of Kelmarsh_WT_03 for FedAvg with intra_farm\n",
      "Finetuning of Kelmarsh_WT_04 for FedAvg with intra_farm\n",
      "Finetuning of Kelmarsh_WT_05 for FedAvg with intra_farm\n",
      "Finetuning of Kelmarsh_WT_06 for FedAvg with intra_farm\n",
      "Finetuning of EDP_WT_01 for FedAvg with intra_farm\n",
      "Finetuning of EDP_WT_06 for FedAvg with intra_farm\n",
      "Finetuning of EDP_WT_07 for FedAvg with intra_farm\n",
      "Finetuning of EDP_WT_11 for FedAvg with intra_farm\n",
      "Finetuning of the cross_farm algorithms\n",
      "Finetuning of FedAvg\n",
      "Finetuning of Penmanshiel_WT_11 for FedAvg with cross_farm\n",
      "Finetuning of Penmanshiel_WT_12 for FedAvg with cross_farm\n",
      "Finetuning of Penmanshiel_WT_13 for FedAvg with cross_farm\n",
      "Finetuning of Penmanshiel_WT_14 for FedAvg with cross_farm\n",
      "Finetuning of Kelmarsh_WT_03 for FedAvg with cross_farm\n",
      "Finetuning of Kelmarsh_WT_04 for FedAvg with cross_farm\n",
      "Finetuning of Kelmarsh_WT_05 for FedAvg with cross_farm\n",
      "Finetuning of Kelmarsh_WT_06 for FedAvg with cross_farm\n",
      "Finetuning of EDP_WT_01 for FedAvg with cross_farm\n",
      "Finetuning of EDP_WT_06 for FedAvg with cross_farm\n",
      "Finetuning of EDP_WT_07 for FedAvg with cross_farm\n",
      "Finetuning of EDP_WT_11 for FedAvg with cross_farm\n",
      "\n",
      "\n",
      "Preparing clients from 2016-12-01 18:30:00 to 2017-03-23 18:30:00\n",
      "\n",
      "Created client Penmanshiel turbine WT_11 with 3779\n",
      "Created client Penmanshiel turbine WT_12 with 2539\n",
      "Created client Penmanshiel turbine WT_13 with 3373\n",
      "Created client Penmanshiel turbine WT_14 with 3097\n",
      "__________________________________________________________\n",
      "Created client Kelmarsh turbine WT_03 with 11315\n",
      "Created client Kelmarsh turbine WT_04 with 9029\n",
      "Created client Kelmarsh turbine WT_05 with 11332\n",
      "Created client Kelmarsh turbine WT_06 with 11797\n",
      "__________________________________________________________\n",
      "Created client EDP turbine WT_01 with 15976\n",
      "Created client EDP turbine WT_06 with 15961\n",
      "Created client EDP turbine WT_07 with 15667\n",
      "Created client EDP turbine WT_11 with 16129\n",
      "__________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training of the intra_farm algorithms\n",
      "Training of FedAvg\n",
      "\n",
      "\n",
      "\n",
      "Penmanshiel\n",
      "\n",
      "\n",
      "Kelmarsh\n",
      "\n",
      "\n",
      "EDP\n",
      "\n",
      "\n",
      "\n",
      "Training of the cross_farm algorithms\n",
      "Training of FedAvg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Finetuning\n",
      "Finetuning of the intra_farm algorithms\n",
      "Finetuning of FedAvg\n",
      "Finetuning of Penmanshiel_WT_11 for FedAvg with intra_farm\n",
      "Finetuning of Penmanshiel_WT_12 for FedAvg with intra_farm\n",
      "Finetuning of Penmanshiel_WT_13 for FedAvg with intra_farm\n",
      "Finetuning of Penmanshiel_WT_14 for FedAvg with intra_farm\n",
      "Finetuning of Kelmarsh_WT_03 for FedAvg with intra_farm\n",
      "Finetuning of Kelmarsh_WT_04 for FedAvg with intra_farm\n",
      "Finetuning of Kelmarsh_WT_05 for FedAvg with intra_farm\n",
      "Finetuning of Kelmarsh_WT_06 for FedAvg with intra_farm\n",
      "Finetuning of EDP_WT_01 for FedAvg with intra_farm\n",
      "Finetuning of EDP_WT_06 for FedAvg with intra_farm\n",
      "Finetuning of EDP_WT_07 for FedAvg with intra_farm\n",
      "Finetuning of EDP_WT_11 for FedAvg with intra_farm\n",
      "Finetuning of the cross_farm algorithms\n",
      "Finetuning of FedAvg\n",
      "Finetuning of Penmanshiel_WT_11 for FedAvg with cross_farm\n",
      "Finetuning of Penmanshiel_WT_12 for FedAvg with cross_farm\n",
      "Finetuning of Penmanshiel_WT_13 for FedAvg with cross_farm\n",
      "Finetuning of Penmanshiel_WT_14 for FedAvg with cross_farm\n",
      "Finetuning of Kelmarsh_WT_03 for FedAvg with cross_farm\n",
      "Finetuning of Kelmarsh_WT_04 for FedAvg with cross_farm\n",
      "Finetuning of Kelmarsh_WT_05 for FedAvg with cross_farm\n",
      "Finetuning of Kelmarsh_WT_06 for FedAvg with cross_farm\n",
      "Finetuning of EDP_WT_01 for FedAvg with cross_farm\n",
      "Finetuning of EDP_WT_06 for FedAvg with cross_farm\n",
      "Finetuning of EDP_WT_07 for FedAvg with cross_farm\n",
      "Finetuning of EDP_WT_11 for FedAvg with cross_farm\n",
      "\n",
      "\n",
      "Preparing clients from 2016-12-01 18:30:00 to 2017-04-06 18:30:00\n",
      "\n",
      "Created client Penmanshiel turbine WT_11 with 4516\n",
      "Created client Penmanshiel turbine WT_12 with 2906\n",
      "Created client Penmanshiel turbine WT_13 with 4201\n",
      "Created client Penmanshiel turbine WT_14 with 3650\n",
      "__________________________________________________________\n",
      "Created client Kelmarsh turbine WT_03 with 12317\n",
      "Created client Kelmarsh turbine WT_04 with 10098\n",
      "Created client Kelmarsh turbine WT_05 with 12116\n",
      "Created client Kelmarsh turbine WT_06 with 12798\n",
      "__________________________________________________________\n",
      "Created client EDP turbine WT_01 with 17992\n",
      "Created client EDP turbine WT_06 with 17977\n",
      "Created client EDP turbine WT_07 with 17683\n",
      "Created client EDP turbine WT_11 with 18145\n",
      "__________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training of the intra_farm algorithms\n",
      "Training of FedAvg\n",
      "\n",
      "\n",
      "\n",
      "Penmanshiel\n",
      "\n",
      "\n",
      "Kelmarsh\n",
      "\n",
      "\n",
      "EDP\n",
      "\n",
      "\n",
      "\n",
      "Training of the cross_farm algorithms\n",
      "Training of FedAvg\n",
      "\n",
      "\n",
      "Federated Training round number 1 \n",
      "Execution time of training_round is 89.28 second\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 9.97 GiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 875.08 MiB is allocated by PyTorch, and 9.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mstart_exp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\goa7\\Documents\\FL_code\\NBM\\exp_utils.py:152\u001b[0m, in \u001b[0;36mstart_exp\u001b[1;34m(exp, model, RESET, SKIP, SKIP_LOCAL, SKIP_FINETUNING, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;66;03m# Start and save the training \u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m         federated_training(model, cross_farm, algo, clients, clients_penmanshiel, clients_kelmarsh, clients_EDP, Path, RESET\u001b[38;5;241m=\u001b[39mRESET, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# Finetuning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\goa7\\Documents\\FL_code\\NBM\\exp_utils.py:56\u001b[0m, in \u001b[0;36mfederated_training\u001b[1;34m(model, cross_farm, algo, clients, clients_penmanshiel, clients_kelmarsh, clients_EDP, Path, RESET, **kwargs)\u001b[0m\n\u001b[0;32m     54\u001b[0m server \u001b[38;5;241m=\u001b[39m FedAvg(model_class\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel_class, client_list\u001b[38;5;241m=\u001b[39mcopy\u001b[38;5;241m.\u001b[39mdeepcopy(clients), init_state_dict \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstate_dict()), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(Path\u001b[38;5;241m.\u001b[39mcreate_full_path(is_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, log\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(Path\u001b[38;5;241m.\u001b[39mcreate_full_path(is_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, log\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)) \u001b[38;5;129;01mor\u001b[39;00m RESET:\n\u001b[1;32m---> 56\u001b[0m     \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluation_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearlystopping\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearlystopping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m     Path\u001b[38;5;241m.\u001b[39mcreate_full_path(is_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     58\u001b[0m     server\u001b[38;5;241m.\u001b[39mlogs\u001b[38;5;241m.\u001b[39msave(file_dir\u001b[38;5;241m=\u001b[39mPath\u001b[38;5;241m.\u001b[39mpath, file_name\u001b[38;5;241m=\u001b[39mPath\u001b[38;5;241m.\u001b[39mfile_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\goa7\\Documents\\FL_code\\NBM\\../federated_learning\\FederatedAlgorithms.py:92\u001b[0m, in \u001b[0;36mServer.training\u001b[1;34m(self, round_number, show, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_round()\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation_args\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m---> 92\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevaluation_args\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ES \u001b[38;5;129;01mand\u001b[39;00m i\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_from_round:\n\u001b[0;32m     95\u001b[0m     new_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmonitor_key][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Must be a 1D list of values (not per client)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\goa7\\Documents\\FL_code\\NBM\\../federated_learning\\FederatedAlgorithms.py:142\u001b[0m, in \u001b[0;36mServer.evaluate\u001b[1;34m(self, list_evaluate_args, model, first_call)\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogs\u001b[38;5;241m.\u001b[39mpop(evaluate_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation(model \u001b[38;5;241m=\u001b[39m model, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mevaluate_args)\n",
      "File \u001b[1;32mc:\\Users\\goa7\\Documents\\FL_code\\NBM\\../federated_learning\\FederatedAlgorithms.py:155\u001b[0m, in \u001b[0;36mServer.evaluation\u001b[1;34m(self, evaluation_mode, model, logging, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m dict_training_loss \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m client \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient_list:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;66;03m# Computed by the client\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m     dict_training_loss[client\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluation_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logging:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogs\u001b[38;5;241m.\u001b[39madd_value(key, dict_training_loss)\n",
      "File \u001b[1;32mc:\\Users\\goa7\\Documents\\FL_code\\NBM\\../federated_learning\\Client.py:134\u001b[0m, in \u001b[0;36mClient.evaluation\u001b[1;34m(self, evaluation_mode, model, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evaluation_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_X_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y_train\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evaluation_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_metrics\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mkeys(), \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeed to pass a metric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\goa7\\Documents\\FL_code\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\goa7\\Documents\\FL_code\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\goa7\\Documents\\FL_code\\NBM\\../federated_learning\\Models.py:77\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLSTM_layers)):\n\u001b[1;32m---> 77\u001b[0m         x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLSTM_layer_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout:\n\u001b[0;32m     79\u001b[0m             x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM_dropout_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)(x)\n",
      "File \u001b[1;32mc:\\Users\\goa7\\Documents\\FL_code\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\goa7\\Documents\\FL_code\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\goa7\\Documents\\FL_code\\.venv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:878\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    875\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 878\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    882\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 9.97 GiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 875.08 MiB is allocated by PyTorch, and 9.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "start_exp(exp=exp, model= model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
